{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import nltk\n",
    "from gensim.models import Word2Vec\n",
    "import re\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"post.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wpt = nltk.WordPunctTokenizer()\n",
    "stop_words = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_tokenizing(df):\n",
    "    token_list=[]\n",
    "    phrase_list=[]\n",
    "    token_df=pd.DataFrame()\n",
    "    token_df.insert(0,'Post',None)\n",
    "    token_df.insert(1,'class',None)\n",
    "    for val in df.values:\n",
    "        append_list=[]\n",
    "        filter_val=re.sub(r'Q:','',val[0])\n",
    "        filter_val=re.sub(r'&#039;[a-z]{1}','',filter_val)\n",
    "        filter_val=re.sub('<[a-z]+>',' ',filter_val).lower()\n",
    "        value=re.sub(r'[^a-zA-Z\\s]', '', filter_val, re.I|re.A)\n",
    "        filter_tokens=[token for token in wpt.tokenize(value) if token not in stop_words and len(token)>=3]\n",
    "        if(filter_tokens):\n",
    "            join_words=' '.join(filter_tokens)\n",
    "            append_list.append(join_words)\n",
    "            append_list.append(val[1])\n",
    "            token_df.loc[len(token_df)]=append_list\n",
    "    return token_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_vector_calculation(token_df):   \n",
    "    cores = multiprocessing.cpu_count()\n",
    "    docs_vectors = pd.DataFrame() \n",
    "    token_list=[]\n",
    "    for val in token_df.values:\n",
    "        token_list.append(val[0].split(' '))\n",
    "    embeddings=Word2Vec(token_list,min_count=20,\n",
    "                     window=2,\n",
    "                     size=50,\n",
    "                     sample=6e-5, \n",
    "                     alpha=0.03, \n",
    "                     min_alpha=0.0007, \n",
    "                     negative=20,\n",
    "                     workers=cores-1)\n",
    "    count=0\n",
    "    for doc in token_list:\n",
    "        count=count+1\n",
    "        temp = pd.DataFrame() \n",
    "        for word in doc: \n",
    "            if word in embeddings.wv.vocab:\n",
    "                word_vec = embeddings[word] \n",
    "                temp = temp.append(pd.Series(word_vec), ignore_index = True) \n",
    "        doc_vector = temp.mean() \n",
    "        docs_vectors = docs_vectors.append(doc_vector, ignore_index = True) \n",
    "        print(count)\n",
    "    docs_vectors['class']=token_df['class']\n",
    "    return docs_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_df=post_tokenizing(df)\n",
    "print(token_df.shape)\n",
    "docs_vectors=post_vector_calculation(token_df) \n",
    "docs_vectors.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_vectors=docs_vectors.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(docs_vectors.drop('class', axis = 1),docs_vectors['class'],test_size = 0.2,\n",
    "                                                   random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=y_train.astype('int')\n",
    "y_test=y_test.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AdaBoostClassifier(n_estimators=800, random_state = 42)\n",
    "model.fit(X_train, y_train)\n",
    "test_pred = model.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "pipe = Pipeline(steps=[('svm', svm.SVC(probability=True))])\n",
    "param_grid = {\n",
    "    'svm__C': [0.1],  \n",
    "    'svm__gamma': [1], \n",
    "    'svm__kernel': ['rbf']}\n",
    "search = GridSearchCV(pipe, param_grid, cv=2, iid=False, refit=True)\n",
    "search.fit(X_train, y_train)\n",
    "print(\"Best CV score = %0.3f:\" % search.best_score_)\n",
    "print(\"Best parameters: \", search.best_params_)\n",
    "\n",
    "SVM_best_params = search.best_params_\n",
    "SVM_best_model = search.best_estimator_\n",
    "print(SVM_best_model)\n",
    "print(SVM_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_svm=search.predict(X_test)\n",
    "accuracy_score(y_test,test_pred_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=pd.read_csv(\"cleanprojectdataset.csv\")\n",
    "token_test_df=post_tokenizing(df_test)\n",
    "docs_vectors_test=post_vector_calculation(token_test_df) \n",
    "pri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(docs_vectors_test.head(5))\n",
    "print(token_test_df['class'].shape)\n",
    "print(token_test_df['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=docs_vectors_test.drop('class', axis = 1).to_numpy()\n",
    "test_data=np.nan_to_num(test_data)\n",
    "test_pred_test=search.predict(test_data)\n",
    "df_test_mod=token_test_df['class']\n",
    "df_test_mod=df_test_mod.astype('int')\n",
    "#df_test_mod=df_test_mod.drop(df_test_mod.index[65])\n",
    "accuracy_score(df_test_mod, test_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_test=model.predict(test_data)\n",
    "df_test_mod=df_test['class']\n",
    "df_test_mod=df_test_mod.drop(df_test_mod.index[65])\n",
    "accuracy_score(df_test_mod, test_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
